<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019-01 on 道法自然</title>
    <link>/categories/2019-01/</link>
    <description>Recent content in 2019-01 on 道法自然</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 26 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/2019-01/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>gRPC入门</title>
      <link>/blog/2019/19-01-26-grpc%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-01-26-grpc%E5%85%A5%E9%97%A8/</guid>
      <description>时间飞逝 如一名携带信息的邮差 但那只不过是我们的比喻 人物是杜撰的 匆忙是假装的 携带的也不是人的讯息
 为什么使用grpc 主要包括以下两点原因：
 protocl buffer一种高效的序列化结构。 支持http 2.0标准化协议。  很对人经常拿thrift跟grpc比较，现在先不发表任何看法，后续会深入thrift进行介绍。
http/2  HTTP/2 enables a more efficient use of network resources and a reduced perception of latency by introducing header field compression and allowing multiple concurrent exchanges on the same connection… Specifically, it allows interleaving of request and response messages on the same connection and uses an efficient coding for HTTP header fields.</description>
    </item>
    
    <item>
      <title>Float的基本介绍</title>
      <link>/blog/2019/19-01-16-float%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-01-16-float%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</guid>
      <description>关于浮点数，为什么它生来就可能存在误差？带着好奇查阅了一些介绍，然后做了简单汇总。这只是一段知识的开始，后续还会继续完善。
—— 荡荡上帝，下民之辟。疾威上帝，其命多辟。天生烝民，其命匪谌。靡不有初，鲜克有终。
 Floating-point represent 浮点数在计算机中是如何表示的？因为它有小数点，那么小数点后面的数，该如何用二进制来表示呢？我们都知道，浮点数本身就存在误差，在工作中，你所使用的float都是一个近似数。这又是什么原因导致的呢？
1. Fixed-point fixed-point 是将bit位拆分成固定的两部分：小数点前的部分和小数点后的部分。拿32 bit的fixed-point表示举例，可以将其中的24 bit用于表示整数部分，剩余的8 bit表示小数部分。
假如要表示1.625，我们可以将小数点后面的第一个bit表示$\frac12$，第二个bit表示1/4，第三个1/8一直到最后一个1/256。最后的表示就是00000000 00000000 00000001 10100000。这样其实也好理解，因为小数点前是从$2^0$开始向左成倍递增，小数点后从$2^{-1}$开始向右递减。
因为小数点后面的部分始终小于1，上面这种表达方式能表达的最大数是255/256。再比这个数小，这种结构就无法表示了。
Floating-point basics 根据上面的思路，我们用二进制表达一下5.5这个十进制数，转化后是$101.1_{(2)}$。继续转换成二进制科学计数法的形式：$1.011_{(2)} * 2^2$。在转换的二进制科学计数法过程中，我们将小数点向左移了2位。就跟转换十进制的效果一样：$101.1_{(10)}$ 的科学计数形式为$1.011 * 10^2$。
对于二进制科学计数法表达的5.5，我们将其拆分成2部分，1.011是一部分，我们称为mantissa。指数2是另一部分，称为exponent。下面我们要将$1.011_{(2)} * 2^2$ 映射到计算机存储的8 bit结构上。
我们用第一个bit来表示正负符号，1表示负数，0表示正数。紧接着的4 bit用来表示exponent + 7后的值。 4 bit最大可以表示到15，这也就意味着当前的exponent不能超过8，不能低于-7。最后的3 bit用于存储mantissa的小数部分。你可能有疑问，它的整数部分怎么办呢？这里我们约定整数部分都调整成1，这样就可以节省1 bit了。举个例子，如果要表示的十进制数是0.5，那么最后的二进制数不是$0.1_{(2)}$，而是$1.0 * 2^{-1}$。最后表示的结果就是：0 1001 011。
再来一个decode的例子，即将0 0101 100还原回原始值。根据之前的描述0101表示的十进制是5，所以exponent = -2，表示回二进制科学计数法的结果：$1.100 * 2^{-2} = 0.011_{(2)}$。我们继续转换成真实精度的数：0.375。
最后可以看在，如果mantissa的长度超过3 bit表示的范围，那么数据的存储就会丢失精度，结果就是一个近似值了。
1. Representable numbers 继续按照上面的思路，现在8 bit的浮点表示能表示的数值区间更大。
要表示最小正数的话，sign置为0，接下来的4 bits置为0000，最后的mantissa也置为000。那么最终的表示结果就是：$1.000_{(2)} * 2^{-7} = 2^{-7} ≈ 0.0079_{(10)}$。</description>
    </item>
    
    <item>
      <title>探讨分布式ID生成系统</title>
      <link>/blog/2019/19-01-11-%E6%8E%A2%E8%AE%A8%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-01-11-%E6%8E%A2%E8%AE%A8%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/</guid>
      <description>全称Universally Unique Identifier，UUID占128bit，也就是16个英文字符的长度（16byte），需要强调的是，它的生成无需中心处理程序。
UUID被用来标识URN(Uniform Resource Names)，对于Transaction ID以及其他需要唯一标志的场景都可以使用它。
UUID是空间和时间上的唯一标识，它长度固定，内部中包含时间信息。如果服务器时间存在不同步的情况，UUID可能会出现重复。
UUID构成 基本格式，由6部分组成：
time-low - time-mide - time-high-and-version - clock-seq-and-reserved &amp;amp; clock-seq-low - node  一个URN示例：f81d4fae-7dec-11d0-a765-00a0c91e6bf6。
因为UUID占128bit，16进制数占4bit，所以转换成16进制0-f的字符串总共有32位。组成的各个部分具体由几位16进制表示，请查阅 Namespace Registration Template
因为UUID太长且无序，导致其不适合做MySQL的主键索引。而且MySQL自带的auto-increment功能，选择bigint的话也只占用64bit。
 All indexes other than the clustered index are known as secondary indexes. In InnoDB, each record in a secondary index contains the primary key columns for the row, as well as the columns specified for the secondary index. InnoDB uses this primary key value to search for the row in the clustered index.</description>
    </item>
    
    <item>
      <title>Gin使用</title>
      <link>/blog/2019/19-01-06-gin%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-01-06-gin%E4%BD%BF%E7%94%A8/</guid>
      <description>Gin对net/http包做了封装，支持路由、中间件等特性，极大的方便对Http Server的开发。文章通过一个Test例子，来简要介绍。对于特别基础的部分，请阅读参考文章。
接口测试 Go中testing包为程序自测提供了便利。可以查阅之前写的博客Go test基础用法，对其内容，我还是挺满意的。
使用Postman 对于接口测试，很多情况都在使用Postman这样的工具。首先在本地启动服务，然后在Postman中配置请求的地址和参数、执行请求、查看结果。
这种方式唯一让人不满意的地方在于：每次修改都需要重启服务。跟直接执行一次Test相比，明显多了一步。
使用Test 测试基类 下面的代码作为接口测试的基类。
TestMain中，我们为所有的测试用例指定通用的配置。之后在执行其他Test前，都会先执行TestMain中的代码。有效的避免了代码冗余。
getRouter方法用于返回一个gin的实例。我们将服务的路由重新在Test中指定，并设置了中间件。
testHttpResponse是我们请求处理的核心代码，发送请求，并保存响应到w中
//common_test.go func TestMain(m *testing.M) { //声明执行Test前的操作 gin.SetMode(gin.TestMode) testutils.NewTestApp(&amp;quot;../conf.test.toml&amp;quot;) flag.Parse() os.Exit(m.Run()) } //设置路由，获取框架Gin的实例 func getRouter() *gin.Engine { router := gin.Default() //配置路由，这是我项目中的自定义配置 router.Use(middleware.HeaderProcess()) RouteAPI(router) return router } //统一处理请求返回结果 func testHttpResponse(t *testing.T, r *gin.Engine, req *http.Request, f func(w *httptest.ResponseRecorder) error) { w := httptest.NewRecorder() r.ServeHTTP(w, req) if err := f(w); err != nil { t.Fatal(err) } }  测试用例 下面是具体的测试用例。我们构造了一个Json数据格式的POST请求，然后通过调用testHttpResponse方法来读取接口的响应数据。</description>
    </item>
    
  </channel>
</rss>