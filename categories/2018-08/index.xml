<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2018-08 on 道法自然</title>
    <link>/categories/2018-08/</link>
    <description>Recent content in 2018-08 on 道法自然</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 19 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/2018-08/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>本地缓存BigCache</title>
      <link>/blog/2018/08-19-%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98bigcache/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-19-%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98bigcache/</guid>
      <description>BigCache的作者做了详细的阐述，尽在这里：Writing a very fast cache service with millions of entries in Go。不得不说，作者的表述非常完美，给它点赞。GitHub地址在：github.com/allegro/bigcache。Usage非常简单。
Omitting GC 当map中存储过百万的object时，Go语言自身的GC甚至会影响不相关的请求，即使是对一个空对象做Marsh操作，响应时间也可能在1s以上。所以，如何避免Go默认对map做的Garbage Collector至关重要。
 GC回收heap中对象，所以我们不把对象创建在heap中就可以避过垃圾回收。查阅offheap。 使用freecache. 在map结构的key和value中不存储pointer，这样便可以将map创建在堆上，同时忽略GC的影响。这来源于Go的优化.  Concurrency 为了避免加锁成为系统的瓶颈，BigTable采用了Shared的方式来解决，确实也有点Redis单线程的感觉。将一块大的数据划分成多块小的数据，为小数据块加锁，确实很好的缓解了加锁的瓶颈。这体现出了拆分的思想，突然想到了曾经被面试的问题：“请将2G的数据进行排序”。
我比较好奇它的Hash方法，客户端的key转换为实际存储的hashedKey的过程。请看通过hashedKey获取shard的部分，作者没有使用%取余来实现，而是使用了&amp;amp;与运算来替代，确实很注重细节啊！
说到与运算:0&amp;amp;0=0; 0&amp;amp;1=0; 1&amp;amp;0=0; 1&amp;amp;1=1;，所以，最终拆分个数完全取决与二进制中1的数量。如果shardMask等于3，那就可以拆分成4份，如果等于4，那结果就是2份，以此类推。
//通过客户端的key获取实际存储的key // Sum64 gets the string and returns its uint64 hash value. func (f fnv64a) Sum64(key string) uint64 { var hash uint64 = offset64 for i := 0; i &amp;lt; len(key); i++ { hash ^= uint64(key[i]) hash *= prime64 } return hash } //通过实际存储的key获取shard块，使用与运算。 func (c *BigCache) getShard(hashedKey uint64) (shard *cacheShard) { return c.</description>
    </item>
    
    <item>
      <title>Golang下的Error</title>
      <link>/blog/2018/08-11-golang%E4%B8%8B%E7%9A%84error/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-11-golang%E4%B8%8B%E7%9A%84error/</guid>
      <description>感觉error确实没啥可说的，这个简单到极致的package总共也不超过10行有效代码。而且常用的fmt也提供了很方便的返回error的方法：
// Package errors implements functions to manipulate errors. package errors // New returns an error that formats as the given text. func New(text string) error { return &amp;amp;errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s }  自定义error error设计的如此简单，导致其判断错误类型就比较麻烦。比如我想判断MySQL的报错是否由主键冲突导致，我可以这样处理：
const PrimaryKeyDuplicateCode = &amp;quot;1062&amp;quot; if strings.Contains(err.Error(), PrimaryKeyDuplicateCode) { //commands }  这样的判断逻辑，如果仅是用于特殊情况，还勉强可以接收。但如果你要整个项目都使用这种形式的话，就会觉得精神崩溃，心理无法承受（反正我是这样感觉的）。所以，我们要自定义实现一个Error结构。当然，这样搞还有syscall这个package。</description>
    </item>
    
    <item>
      <title>Shell必备基础（1）</title>
      <link>/blog/2018/08-09-shell%E5%BF%85%E5%A4%87%E5%9F%BA%E7%A1%801/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-09-shell%E5%BF%85%E5%A4%87%E5%9F%BA%E7%A1%801/</guid>
      <description>Shell是对Linux命令的深加工，用得好，事半功倍。 本来只想加深Array的用法，但一不小心，又变成了一篇基础大全。
比较运算 习惯在if语句中使用[[...]]对条件进行比较，字符串、数值以及文件，统统笑纳。
算数比较 常用的操作符有-eq、-ne、-gt、-lt、-le等。
文件系统 当编译文件、或者查看pid文件、日志时会经常用到。
[ -e $var ] 如果指定的变量包含的文件存在，则返回真 [ -f $var ] 如果指定的变量包含正常的文件路径或文件名，则返回真  字符串比较 判空还是相当常见的操作。比如，查看当前系统是否启用了notify的进程，如果有的话，kill掉。
pid=`ps -ef | grep notify | grep -v &#39;grep&#39; | awk &#39;{print $2}&#39;` if [[ -n $pid ]] then echo -e &amp;quot;\033[31m Kill掉当前正在运行的进程... \033[0m\n&amp;quot; kill $pid fi  常见的操作符如下：
[[ -z $str ]] 如果str包含的是空字符串，则返回真 [[ -n $str ]] 如果str包含的是非空字符串，则返回真  其他的操作符包括：==、!=、&amp;gt;、&amp;lt;
逻辑运算 使用逻辑&amp;amp;&amp;amp;和||来表示与和或的逻辑关系。
比如
if [[ -n $str ]] &amp;amp;&amp;amp; [[ -z $str ]] then echo $str fi  基本语句Example if语句 if command1 then # .</description>
    </item>
    
    <item>
      <title>Git撤销本地修改</title>
      <link>/blog/2018/08-07-git%E6%92%A4%E9%94%80%E6%9C%AC%E5%9C%B0%E4%BF%AE%E6%94%B9/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-07-git%E6%92%A4%E9%94%80%E6%9C%AC%E5%9C%B0%E4%BF%AE%E6%94%B9/</guid>
      <description>版本：0.02
用了git就会发现，再也不想用svn了。
Note：在执行push操作前，所有的修改都发生在本地，可以使用reset随便回滚本地的提交。但要注意：本地修改一旦回滚，无法找回。在push后，想要回滚到指定的版本，便需要使用revert，这样的代价就是：你的回滚记录被记录在了log中，所有人都可以看见。
使用reset回退 本质上是commit操作的回退。Git工作流可以简化为三个部分：Working Directory、index、HEAD。后两部分对应的git命令便是add和commit。如果使用的是Sourcetree工具，那么这三部分就更直观了。
该命令的具体功能是移动HEAD，即移动分支的指针。将当前的HEAD重新指向之前的版本，本地工作环境也会跟着切换。适用场景：本地已经commit，但尚未push到远端仓库的回滚操作。
该命令提供了三个属性：分别是soft、mixed、和hard。
 soft撤销上一次的commit命令，返回到HEAD前的index状态。 mixed撤销了上一次的git add和git commit命令，将index的修改回滚到Working Directory。 hard撤销了最后git add 和 git commit 命令以及工作目录中的所有修改。  所以reset重写的顺序如下：
 移动 HEAD 指向的分支（如果是soft，则到此停止）。 使索引看起来像 HEAD（如果是mixed，则到此停止）。 使工作目录看起来像索引。  Example 当执行pull命令发生冲突时时，本地代码需要做merge操作。但本地代码只是临时调试修改，并不需要保存提交。执行如下命令，便会清空本地的修改，hard相当于一个版本的指针，origin/master可以替换为具体的版本号
git reset --hard origin/master git reset --hard version-number git reset --hard HEAD  获取版本号可以通过git log直接查看。
更多详细介绍，可以查看： 高级合并及 重置揭密
checkout stash储藏 将==工作区==的修改进行存储，使本地重新成为一个干净的环境，同时方便在之后应用这些改动。可以用于存储==已被索引的文件==、或者==未跟踪的文件==。执行git stash -a来暂存所有改动的文件。
下面是执行的流程：
 git stash 储藏修改 git stash list 查看储藏的列表 将储藏重新应用到当前分支：git statsh apply stash@{1}或者git stash pop stash@{1}。后者会在应用暂存之后从堆栈上删除 git stash drop stash@{1} 移除暂存  使用clean清空 用于从==工作区==移除==未被追踪的文件==，执行git clean -d -f来移除所有未被追踪的文件或目录。</description>
    </item>
    
    <item>
      <title>IP Routing</title>
      <link>/blog/2018/08-04-ip-routing/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-04-ip-routing/</guid>
      <description> 假设你在跟小米公司对接服务，那你有没有好奇过：自家的服务器是如何找到小米公司的服务器的。为了安全，公司的服务器可都是在内网的，用户是无法直接访问到的。好好了解一下Ip Routing，它可以给你部分答案。
概述 当主机IP(Network)层收到一个datagram后，它首先会检查datagram的目标主机是不是自己。如果是，那么它会将datagram发送给其他协议处理。如果不是，它便检查自己是否被配置作为一个路由。如果是，它将按照规则将datagram继续传递。否则，默默的把datagram丢掉。
所有routing提供的IP地址，都假设下一个hop是离目标地址最近的。在datagram传递的过程中，我们会修改link-layer的地址为下一个hop的地址，而Destination IP一般是不做修改的。
Routing Table 在命令行执行 netstat -rn，查看系统的routing table。
# 展示结果做了修改，非真实值 neojos@BJ ~ $ netstat -rn Kernel IP routing table Destination Gateway Genmask Flags MSS Window irtt Iface 140.168.0.0 10.3.206.240 255.255.0.0 UG 0 0 0 eth0  了解Falgs参数：  U 表示当前路由是在使用的 G 表示路由到一个gateway。如果没有设置该flag，则表示跟Destination是直接连接的。 H 表示路由到一个主机地址。如果没有设置该flag，则Destination是一个网络地址。 D 表示路由是通过ICMP Redirect设置的。一般来说，Redirect设置的route都是主机地址。  路由查询的顺序：  查找匹配的主机地址 查找匹配的网络地址 查找default的路由。  Host unreachable 当route没有找到destination时，Destination Host Unreachable的错误会返回给源主机。你可以通过ping路由表中配置错误的destination host address来查看。
ICMP Redirect Error </description>
    </item>
    
    <item>
      <title>ngrep抓包</title>
      <link>/blog/2018/08-01-ngrep%E6%8A%93%E5%8C%85/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/08-01-ngrep%E6%8A%93%E5%8C%85/</guid>
      <description>简单的工具其实挺有用的。警告：不许瞧不起工具，尤其是你还不会用的工具。
ngrep还是之前跟花椒直播的同事对接项目时，了解到的一个工具。它可以用来抓取服务器上通过网卡的所有请求。跟tcpdump差不多，但却更简单。tcpdump需要借助Wireshark才可以将请求完美展示出来，但这个就跟使用grep一样。
以前专门请教过一个同事如何使用Wireshark分析网络请求，自己也专门看了相关的Wireshark操作。但最终却发现，如果是抓客户端的请求(非分析TCP)，Wireshark使用起来并不方便。而如果分析的是服务端之间的请求，还需要借助tcpdump先来把请求记录下来，然后再到Wireshark中打开分析。
Example 经常使用的模式
# 匹配特定host ngrep -q host api.open.huajiao.com -d any -W byline # 匹配特定host和端口 ngrep –q host api.open.huajiao.com and port 80 –W byline # 报文中包含&amp;quot;search&amp;quot;关键字 ngrep –q –W byline &amp;quot;search&amp;quot; host www.google.com and port 80  Options 详细还是通过man直接查看工具说明吧！这里列举一个：
-d By default ngrep will select a default interface to listen on. Use this option to force ngrep to listen on interface dev.  结果示例 以下是命令输出的结果，跟curl是不是很像：
interface: any filter: ( host api.</description>
    </item>
    
  </channel>
</rss>